{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LzBqoWNBpyG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'"
      ],
      "metadata": {
        "id": "CGdkE4eyCg4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56qsBBWvQf92",
        "outputId": "ebf477da-efe0-4305-fc6e-6aa69dd66472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs =5\n",
        "batch_size =4\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "qrIw0uC9CwsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n"
      ],
      "metadata": {
        "id": "kpeg53SyC7Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(root='data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lbd8zT6DJEq",
        "outputId": "b2b99b19-4035-4fa4-f9fa-1c79bcad5f63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "aXPsBTS_DvbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clases = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "GqJrRz1cD-bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(w-f+2p)/s +1\n",
        "(32-5+2*p)/s +"
      ],
      "metadata": {
        "id": "A5kea8fIJBGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "      def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6,3, padding=(1,1))\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(6, 12,3, padding=(1,1))\n",
        "        self.conv3 = nn.Conv2d(12, 16,3, padding=(1,1))\n",
        "        self.drop = nn.Dropout(0.2)\n",
        "        self.fc1 = nn.Linear(16*4*4,120)\n",
        "        self.fc2 = nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,10)\n",
        "\n",
        "      def forward(self,x):\n",
        "        # -> n, 3, 32, 32\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 16, 16\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 12, 8, 8\n",
        "        x = self.pool(F.relu(self.conv3(x))) #  -> 16,4,4\n",
        "        x = x.view(-1, 16 * 4 * 4)            # -> n, 400\n",
        "        x = self.drop(F.relu(self.fc1(x)))               # -> n, 120\n",
        "        x = self.drop(F.relu(self.fc2(x)))               # -> n, 84\n",
        "        x = self.fc3(x)                       # -> n, 10\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "RTTGZ_TEEVmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNet().to(device)"
      ],
      "metadata": {
        "id": "8RJQqT__EpA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=0.001)\n"
      ],
      "metadata": {
        "id": "nYDbkuVrEwWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH8v-fVTUQ1U",
        "outputId": "dca66e93-37ea-49f1-87ed-0ff125055ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 6, 32, 32]             168\n",
            "         MaxPool2d-2            [-1, 6, 16, 16]               0\n",
            "            Conv2d-3           [-1, 12, 16, 16]             660\n",
            "         MaxPool2d-4             [-1, 12, 8, 8]               0\n",
            "            Conv2d-5             [-1, 16, 8, 8]           1,744\n",
            "         MaxPool2d-6             [-1, 16, 4, 4]               0\n",
            "            Linear-7                  [-1, 120]          30,840\n",
            "           Dropout-8                  [-1, 120]               0\n",
            "            Linear-9                   [-1, 84]          10,164\n",
            "          Dropout-10                   [-1, 84]               0\n",
            "           Linear-11                   [-1, 10]             850\n",
            "================================================================\n",
            "Total params: 44,426\n",
            "Trainable params: 44,426\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.10\n",
            "Params size (MB): 0.17\n",
            "Estimated Total Size (MB): 0.28\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
        "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 2000 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "PATH = './cnn.pth'\n",
        "torch.save(model.state_dict(), PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFvTrB5AE6pg",
        "outputId": "6268a73a-50ce-4031-cb87-066bca85cfb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [2000/12500], Loss: 2.3084\n",
            "Epoch [1/5], Step [4000/12500], Loss: 2.2694\n",
            "Epoch [1/5], Step [6000/12500], Loss: 2.2902\n",
            "Epoch [1/5], Step [8000/12500], Loss: 2.3102\n",
            "Epoch [1/5], Step [10000/12500], Loss: 2.2915\n",
            "Epoch [1/5], Step [12000/12500], Loss: 2.3316\n",
            "Epoch [2/5], Step [2000/12500], Loss: 2.3209\n",
            "Epoch [2/5], Step [4000/12500], Loss: 2.1236\n",
            "Epoch [2/5], Step [6000/12500], Loss: 2.1293\n",
            "Epoch [2/5], Step [8000/12500], Loss: 2.3456\n",
            "Epoch [2/5], Step [10000/12500], Loss: 2.5528\n",
            "Epoch [2/5], Step [12000/12500], Loss: 2.3801\n",
            "Epoch [3/5], Step [2000/12500], Loss: 1.8929\n",
            "Epoch [3/5], Step [4000/12500], Loss: 1.7236\n",
            "Epoch [3/5], Step [6000/12500], Loss: 1.8090\n",
            "Epoch [3/5], Step [8000/12500], Loss: 1.9257\n",
            "Epoch [3/5], Step [10000/12500], Loss: 1.7186\n",
            "Epoch [3/5], Step [12000/12500], Loss: 2.4115\n",
            "Epoch [4/5], Step [2000/12500], Loss: 1.8875\n",
            "Epoch [4/5], Step [4000/12500], Loss: 1.6269\n",
            "Epoch [4/5], Step [6000/12500], Loss: 1.4190\n",
            "Epoch [4/5], Step [8000/12500], Loss: 1.6605\n",
            "Epoch [4/5], Step [10000/12500], Loss: 1.8149\n",
            "Epoch [4/5], Step [12000/12500], Loss: 1.8745\n",
            "Epoch [5/5], Step [2000/12500], Loss: 1.8970\n",
            "Epoch [5/5], Step [4000/12500], Loss: 2.3146\n",
            "Epoch [5/5], Step [6000/12500], Loss: 2.3495\n",
            "Epoch [5/5], Step [8000/12500], Loss: 1.4269\n",
            "Epoch [5/5], Step [10000/12500], Loss: 1.2297\n",
            "Epoch [5/5], Step [12000/12500], Loss: 1.5859\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad(): # Se deshabilita el siguimiento de los gradientes\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(10)] # Se almacena la cantidad de clases correctas\n",
        "    n_class_samples = [0 for i in range(10)]\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device) # cargamos a dispositivo\n",
        "        labels = labels.to(device) # cargamos a dispositivo\n",
        "        outputs = model(images) # resultadp\n",
        "        _, predicted = torch.max(outputs, 1) # Calcula las predicciones finales del modelo seleccionando el índice de la clase con el valor de probabilidad más alto.\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if (label == pred):\n",
        "                n_class_correct[label] += 1\n",
        "            n_class_samples[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {clases[i]}: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ7zPmfkTVQQ",
        "outputId": "7a2e6cd5-da28-42e2-b0e0-fd38c31234df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network: 36.17 %\n",
            "Accuracy of plane: 39.0 %\n",
            "Accuracy of car: 60.7 %\n",
            "Accuracy of bird: 4.1 %\n",
            "Accuracy of cat: 21.6 %\n",
            "Accuracy of deer: 23.7 %\n",
            "Accuracy of dog: 46.0 %\n",
            "Accuracy of frog: 39.1 %\n",
            "Accuracy of horse: 48.7 %\n",
            "Accuracy of ship: 35.7 %\n",
            "Accuracy of truck: 43.1 %\n"
          ]
        }
      ]
    }
  ]
}